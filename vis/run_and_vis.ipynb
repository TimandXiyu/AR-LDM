{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-19T10:02:22.042405500Z",
     "start_time": "2023-11-19T10:02:20.209997200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "# Clear any command line arguments to avoid conflict with Jupyter arguments\n",
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "# Now you can safely initialize Hydra\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mldadmin/home/s123mdg35_05/miniconda3/envs/ldm/lib/python3.8/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/media/mldadmin/home/s123mdg35_05/miniconda3/envs/ldm/lib/python3.8/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "/media/mldadmin/home/s123mdg35_05/miniconda3/envs/ldm/lib/python3.8/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/media/mldadmin/home/s123mdg35_05/miniconda3/envs/ldm/lib/python3.8/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/media/mldadmin/home/s123mdg35_05/miniconda3/envs/ldm/lib/python3.8/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "from main import ARLDM, DDPStrategy\n",
    "from datasets.flintstones import StoryDataset\n",
    "\n",
    "class CustomStory(StoryDataset):\n",
    "    def __init__(self, args, prompts, subset='test'):\n",
    "        super(CustomStory, self).__init__(subset, args=args)\n",
    "        self.prompts = prompts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Use zeros as placeholders for images\n",
    "        images = torch.zeros([5, 3, 256, 256])\n",
    "        source_images = torch.zeros([5, 3, 224, 224])\n",
    "\n",
    "        # Use the loaded prompts instead of the text from h5\n",
    "        texts = self.prompts[index]\n",
    "\n",
    "        # Tokenize caption using CLIPTokenizer\n",
    "        tokenized = self.clip_tokenizer(\n",
    "            texts[1:] if self.args.task == 'continuation' else texts,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        captions, attention_mask = tokenized['input_ids'], tokenized['attention_mask']\n",
    "\n",
    "        # Tokenize caption using blip tokenizer\n",
    "        tokenized = self.blip_tokenizer(\n",
    "            texts,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        source_caption, source_attention_mask = tokenized['input_ids'], tokenized['attention_mask']\n",
    "\n",
    "        return images, captions, attention_mask, source_images, source_caption, source_attention_mask\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T10:02:22.850636600Z",
     "start_time": "2023-11-19T10:02:22.043407100Z"
    }
   },
   "id": "b6889a49256b439d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class LightningDataset(pl.LightningDataModule):\n",
    "    def __init__(self, args, prompts=None):\n",
    "        super(LightningDataset, self).__init__()\n",
    "        self.kwargs = {\"num_workers\": args.num_workers, \"persistent_workers\": True if args.num_workers > 0 else False,\n",
    "                       \"pin_memory\": True}\n",
    "        self.args = args\n",
    "        self.prompts = prompts\n",
    "\n",
    "    def setup(self, stage='fit'):\n",
    "        print(self.prompts)\n",
    "        self.test_data = CustomStory(self.args, prompts=self.prompts)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if not hasattr(self, 'trainloader'):\n",
    "            self.trainloader = DataLoader(self.train_data, batch_size=self.args.batch_size, shuffle=True, **self.kwargs)\n",
    "        return self.trainloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        if self.val_data is None:\n",
    "            return None\n",
    "        return DataLoader(self.val_data, batch_size=self.args.batch_size, shuffle=False, **self.kwargs)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.args.batch_size, shuffle=False, **self.kwargs)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.args.batch_size, shuffle=False, **self.kwargs)\n",
    "\n",
    "    def get_length_of_train_dataloader(self):\n",
    "        if not hasattr(self, 'trainloader'):\n",
    "            self.trainloader = DataLoader(self.train_data, batch_size=self.args.batch_size, shuffle=True, **self.kwargs)\n",
    "        return len(self.trainloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T10:02:22.851633900Z",
     "start_time": "2023-11-19T10:02:22.829100500Z"
    }
   },
   "id": "15fc7fe973864210"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    ['Fred and dino are driving a car in a sunny day.', \n",
    "     '<char> stopped them on the way.',\n",
    "     '<char> talked to Fred and dino with angry face because they are driving too fast.',\n",
    "     'Fred and dino are confused and asked <char> what they should do.',\n",
    "     '<char> gave them a ticket and told them to report to police station.']\n",
    "]\n",
    "\n",
    "def sample_from_prompts(args):\n",
    "    print(f'loading from checkpoint: {args.test_model_file}')\n",
    "    assert args.test_model_file is not None, \"test_model_file cannot be None\"\n",
    "    dataloader = LightningDataset(args, prompts=prompts)\n",
    "    dataloader.setup()\n",
    "\n",
    "    model = ARLDM.load_from_checkpoint(args.test_model_file, args=args, strict=False)\n",
    "\n",
    "    predictor = pl.Trainer(\n",
    "        accelerator='gpu',  # 'gpu' is still valid for single GPU\n",
    "        devices=1,  # Specify 1 GPU, you can also pass an index e.g., [0]\n",
    "        max_epochs=-1,  # This setting might not be valid for single GPU; set an actual number of epochs\n",
    "        benchmark=True,  # This can be set to False since benchmarking is more useful for multi-GPU setups\n",
    "        precision=16  # FP16 precision can still be used for single GPU\n",
    "    )\n",
    "\n",
    "    predictions = predictor.predict(model, dataloader)\n",
    "    images = [elem for sublist in predictions for elem in sublist[0]]\n",
    "\n",
    "    return images, predictions\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T10:02:22.923711600Z",
     "start_time": "2023-11-19T10:02:22.833101300Z"
    }
   },
   "id": "377a79cac6df5f2"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "results = None\n",
    "\n",
    "@hydra.main(config_path=\"/media/mldadmin/home/s123mdg35_05/ar-ldm/\", config_name=\"config\")\n",
    "def main(args):\n",
    "    global results\n",
    "    pl.seed_everything(args.seed)\n",
    "    results = sample_from_prompts(args)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T10:11:48.130585500Z",
     "start_time": "2023-11-19T10:11:48.111625300Z"
    }
   },
   "id": "d74a6fa1d740c917"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from checkpoint: /media/mldadmin/home/s123mdg35_05/ar-ldm/ckpts/flintstones_ada_pinkhat/epoch=99-step=1300.ckpt\n",
      "[['Fred and dino are driving a car in a sunny day.', '<char> stopped them on the way.', '<char> talked to Fred and dino with angry face because they are driving too fast.', 'Fred and dino are confused and asked <char> what they should do.', '<char> gave them a ticket and told them to report to police station.']]\n",
      "clip 4 new tokens added\n",
      "blip 1 new tokens added\n",
      "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Fred and dino are driving a car in a sunny day.', '<char> stopped them on the way.', '<char> talked to Fred and dino with angry face because they are driving too fast.', 'Fred and dino are confused and asked <char> what they should do.', '<char> gave them a ticket and told them to report to police station.']]\n",
      "clip 4 new tokens added\n",
      "blip 1 new tokens added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12872dc95b3048ba90c6f5931d384404"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # reset the working directory\n",
    "    os.chdir(os.path.join(os.getcwd(), '/media/mldadmin/home/s123mdg35_05/ar-ldm/'))\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T10:12:33.084169100Z",
     "start_time": "2023-11-19T10:11:49.693281700Z"
    }
   },
   "id": "25c7ea130cdaaf71"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[<PIL.Image.Image image mode=RGB size=256x256 at 0x7F6BA5729B20>,\n <PIL.Image.Image image mode=RGB size=256x256 at 0x7F6BA57295E0>,\n <PIL.Image.Image image mode=RGB size=256x256 at 0x7F6BA5729C40>,\n <PIL.Image.Image image mode=RGB size=256x256 at 0x7F6BA5729BB0>,\n <PIL.Image.Image image mode=RGB size=256x256 at 0x7F6BA57290D0>]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, predictions = results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T10:12:44.208784700Z",
     "start_time": "2023-11-19T10:12:44.201019800Z"
    }
   },
   "id": "7828b4001e8b91a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display PIL images\n",
    "def display_images(images):\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    columns = 5\n",
    "    rows = 1\n",
    "    for i in range(1, columns * rows + 1):\n",
    "        img = images[i-1]\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "display_images(images)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a394c003cb77c5d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
